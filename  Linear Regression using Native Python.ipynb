{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "You will be building  - Linear Regression. But before you build a model, \n",
    "you will need to have a method to extract the data and process it in your data frames and convert to numpy.  Y0ou have already\n",
    "Complete the functions, readdata (similar to assignment 2), train, classify and LinRegaccuracy.\n",
    "I have called the functions in the main program.\n",
    "\n",
    "NASA data set, obtained from a series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade \n",
    "sections conducted in an anechoic wind tunnel. The data set comprises different size NACA 0012 airfoils at various wind \n",
    "tunnel speeds and angles of attack. The span of the airfoil and the observer position were the same in all of the experiments. \n",
    "The data set has 6 attributes as given below. \n",
    "Now you will read a dataset for Machine Learning using pandas\n",
    "filename = \"airfoil_self_noise.dat.txt\"\n",
    "This is tab separated file with no headers\n",
    "Use appropriate command to read this data file and store the data into dataframe.\n",
    "After that convert it to numpy\n",
    "Then use numpy to split the data into training and test set.\n",
    "The training data should have 80% of data, and the test data should ahve 20% data.\n",
    "DO NOT USE SKLEARN LIBRARY\n",
    "Details of Data set:\n",
    "Attribute Information:\n",
    "\n",
    "This problem has the following inputs:\n",
    "(Attributes 1 to 5 form X_data) \n",
    "1. Frequency, in Hertzs. \n",
    "2. Angle of attack, in degrees. \n",
    "3. Chord length, in meters. \n",
    "4. Free-stream velocity, in meters per second. \n",
    "5. Suction side displacement thickness, in meters. \n",
    "\n",
    "The only output is (and Y_data): \n",
    "6. Scaled sound pressure level, in decibels. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and splitting Dataset into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Complete this function from the 2nd assignment on Pandas. SOme minor modificatiosn in the parameters\n",
    "Be sure to feature scale and normalize\n",
    "'''\n",
    "def readdata(filename, cols, delim = \"\\t\"):\n",
    "    df = pd.read_csv(filename,sep='\\t',header=(0),names=cols)\n",
    "    print('===================Original Data==============================================')\n",
    "    print(df.head())\n",
    "    x=df.drop([\"ScaledSoundPressureLevel\"],axis=1)\n",
    "    y=df[\"ScaledSoundPressureLevel\"]\n",
    "    print(x.head())\n",
    "    print(\",............................................\")\n",
    "    #print(y)\n",
    "    \n",
    "    #scale the data\n",
    "    scaler = MinMaxScaler() \n",
    "    scaled_values = scaler.fit_transform(x) \n",
    "   \n",
    "    print('==========================After scaling=======================================')\n",
    "    print(scaled_values) # it is a numpy array, alternatively df.to_numpy()\n",
    "    X_data=scaled_values  #taking X all cols exept target col\n",
    "    Y_data=y.to_numpy()\n",
    "    \n",
    "    \n",
    "    num_training = int(0.8 * X_data.shape[0]) # 80% of the X data, taking the index \n",
    "    \n",
    "    x_data_train_1=0.80*X_data\n",
    "\n",
    "# split the actual data\n",
    "    x_data_train, x_data_test = X_data[:num_training], X_data[num_training:]\n",
    "    y_data_train, y_data_test = Y_data[:num_training], Y_data[num_training:]\n",
    "    print('==========================Train Test Split=======================================')\n",
    "    print('x_data_train',x_data_train.shape)\n",
    "    print('y_data_train',y_data_train.shape)\n",
    "    print('x_data_test',x_data_test.shape)\n",
    "    print('y_data_test',y_data_test.shape)\n",
    "    print('=====================')\n",
    "    print('y_data_test',x_data_train_1.shape)\n",
    "    return x_data_train, y_data_train, x_data_test, y_data_test,x_data_train_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Original Data==============================================\n",
      "   Frequency  AngleOfAttack  ChordLength  FreeStreamVelocity  \\\n",
      "0       1000            0.0       0.3048                71.3   \n",
      "1       1250            0.0       0.3048                71.3   \n",
      "2       1600            0.0       0.3048                71.3   \n",
      "3       2000            0.0       0.3048                71.3   \n",
      "4       2500            0.0       0.3048                71.3   \n",
      "\n",
      "   SuctionSideDisplacementThickness  ScaledSoundPressureLevel  \n",
      "0                          0.002663                   125.201  \n",
      "1                          0.002663                   125.951  \n",
      "2                          0.002663                   127.591  \n",
      "3                          0.002663                   127.461  \n",
      "4                          0.002663                   125.571  \n",
      "   Frequency  AngleOfAttack  ChordLength  FreeStreamVelocity  \\\n",
      "0       1000            0.0       0.3048                71.3   \n",
      "1       1250            0.0       0.3048                71.3   \n",
      "2       1600            0.0       0.3048                71.3   \n",
      "3       2000            0.0       0.3048                71.3   \n",
      "4       2500            0.0       0.3048                71.3   \n",
      "\n",
      "   SuctionSideDisplacementThickness  \n",
      "0                          0.002663  \n",
      "1                          0.002663  \n",
      "2                          0.002663  \n",
      "3                          0.002663  \n",
      "4                          0.002663  \n",
      ",............................................\n",
      "==========================After scaling=======================================\n",
      "[[0.04040404 0.         1.         1.         0.03900472]\n",
      " [0.0530303  0.         1.         1.         0.03900472]\n",
      " [0.07070707 0.         1.         1.         0.03900472]\n",
      " ...\n",
      " [0.19191919 0.7027027  0.27272727 0.19949495 0.90411066]\n",
      " [0.24242424 0.7027027  0.27272727 0.19949495 0.90411066]\n",
      " [0.30808081 0.7027027  0.27272727 0.19949495 0.90411066]]\n",
      "==========================Train Test Split=======================================\n",
      "x_data_train (1201, 5)\n",
      "y_data_train (1201,)\n",
      "x_data_test (301, 5)\n",
      "y_data_test (301,)\n",
      "=====================\n",
      "y_data_test (1502, 5)\n"
     ]
    }
   ],
   "source": [
    "cols = ['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity', 'SuctionSideDisplacementThickness', 'ScaledSoundPressureLevel']\n",
    "x_data_train, y_data_train, x_data_test, y_data_test,x_data_train_1 = readdata('airfoil_self_noise.dat.txt', cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and updating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Complete this function for training.\n",
    "\n",
    "''' \n",
    "def train( x_data_train, y_data_train, l_rate, iterations):\n",
    "    w=np.zeros(5)\n",
    "    b =np.zeros(1)\n",
    "    m=len(x_data_train)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        y_train_pred = np.dot(x_data_train,w)+b\n",
    "        #print(y_train_pred.shape)\n",
    "        \n",
    "        #(\"Calculating cost\")\n",
    "        cost=np.sum(np.power((y_train_pred-y_data_train),2))\n",
    "        dw=(1/m)*np.dot(x_data_train.T,(y_train_pred-y_data_train))\n",
    "        db=(1/m)*np.sum(y_train_pred-y_data_train)\n",
    "        \n",
    "        #Updating Weights\n",
    "        \n",
    "        w=w-l_rate*dw\n",
    " \n",
    "        #Updating Bias\n",
    "    \n",
    "        b=b-l_rate*db \n",
    "        \n",
    "    return w, b,y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b,y_train_pred=train( x_data_train, y_data_train, l_rate=0.01, iterations=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Weights and bias when iterations are 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.9408569 ,   5.6845421 ,  -2.23351551,   2.51821057,\n",
       "       -12.16909591])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), array([125.13675622]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Complete this function for Regression\n",
    "'''\n",
    "def classify(y_data_test,x_data_test, W, b):\n",
    "    print(w.shape)\n",
    "    print(b.shape)\n",
    "    print(x_data_test.shape)\n",
    "    y_pred_test = np.dot(w,x_data_test.T)+b \n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(1,)\n",
      "(301, 5)\n"
     ]
    }
   ],
   "source": [
    "y_pred_test=classify(y_data_test,x_data_test, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_Acc(y_data_train,y_train_pred):\n",
    "    num_accuracy=1-(np.sum(np.abs(y_data_train-y_train_pred)/y_data_train)/len(y_data_train))\n",
    "    return num_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606315150082214"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_Acc(y_data_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955912993729942"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_Acc(y_data_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate way of Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN ACCURACY\n",
    "\n",
    "def LinRegaccuracyTrain(y_data_train, y_train_pred):\n",
    "\n",
    "    total_error = 0\n",
    "    for i in range(0, len(y_data_train)):\n",
    "        errSet= abs((y_train_pred[i] - y_data_train[i]) / y_data_train[i])\n",
    "        total_error += errSet\n",
    "        \n",
    "    total_error = (total_error / len(y_data_train))\n",
    "    accuracyScore = 1 - total_error\n",
    "    return accuracyScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606315150082214"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinRegaccuracyTrain(y_data_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST ACCURACY\n",
    "def LinRegaccuracy(y_data_test, y_pred_test):\n",
    "\n",
    "    total_error = 0\n",
    "    for i in range(0, len(y_data_test)):\n",
    "        errSet= abs((y_pred_test[i] - y_data_test[i]) / y_data_test[i])\n",
    "        total_error += errSet\n",
    "    total_error = (total_error / len(y_data_test))\n",
    "    accuracyScore = 1 - total_error\n",
    "    return accuracyScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955912993729942"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test Accuracy\n",
    "LinRegaccuracy(y_data_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Sqaure Error of test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train:  34.908859724038535\n",
      "MSE test:  42.90191663778914\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE train: \", mean_squared_error(y_data_train, y_train_pred))\n",
    "print(\"MSE test: \", mean_squared_error(y_data_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Mean Square Error of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train:  5.908372002848038\n",
      "RMSE test:  6.5499554683821435\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE train: \", math.sqrt(mean_squared_error(y_data_train, y_train_pred)))\n",
    "print(\"RMSE test: \", math.sqrt(mean_squared_error(y_data_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got Train accuracy- 96.06% and test accuracy as 95.5% when iteraions are 5000 and learning rate is 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
